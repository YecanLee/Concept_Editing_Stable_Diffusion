{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from diffusers.schedulers import LMSDiscreteScheduler\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from transformers import AutoTokenizer, CLIPProcessor, CLIPModel\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './concept/sweetpepper'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    threshold = 0.8\n",
    "    seed = 1024\n",
    "    device = 'cuda'\n",
    "    batch_size = 8\n",
    "    num_inference_steps = 200\n",
    "    concept = 'sweetpepper'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess of the concept\n",
    "concept = Config.concept.replace('_', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the concept dictionary\n",
    "concept_dict = torch.load(f'{output_dir}/output/dictionary.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a ground truth image then do the decomposition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1-base\")\n",
    "pipe.to(\"cuda\")\n",
    "pipe.scheduler = LMSDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.set_progress_bar_config(disable=True)\n",
    "pipe.tokenizer.add_tokens('<>')\n",
    "trained_id = pipe.tokenizer.convert_tokens_to_ids('<>')\n",
    "pipe.text_encoder.resize_token_embeddings(len(pipe.tokenizer))\n",
    "_ = pipe.text_encoder.get_input_embeddings().weight.requires_grad_(False)\n",
    "\n",
    "\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to('cuda')\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "clip_tokenizer = AutoTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "transform_tensor = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept = Config.concept\n",
    "prompt = f'A image of {concept}'\n",
    "generator = torch.Generator(\"cuda\").manual_seed(Config.seed)\n",
    "image = pipe(prompt, guidance_scale=7.5,\n",
    "             generator=generator,\n",
    "             return_dict=False,\n",
    "             num_images_per_prompt=1,\n",
    "             num_inference_steps=Config.num_inference_steps)[0][0]\n",
    "# Display the original image\n",
    "display(image.resize((224, 224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best alphas we got from before\n",
    "alpha_dict = torch.load(f'{output_dir}/best_alphas.pt').detach().require_grad_(False)\n",
    "\n",
    "# debug, check if the alphas are dictionary\n",
    "print(alpha_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha is the weights of different hidden concepts\n",
    "# normalize the weights so they add up to 1\n",
    "alpha_sum = alpha_dict.sum(0)   \n",
    "alpha_normalized = alpha_dict / alpha_sum\n",
    "\n",
    "# sort the weights in descending order, select the weights which sum up to 0.8\n",
    "# this code returns the indices with the descending order\n",
    "alpha_sort = torch.sort(alpha_normalized, descending=True)\n",
    "\n",
    "# debug\n",
    "print(alpha_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted weights\n",
    "alpha_median = alpha_normalized[alpha_sort]\n",
    "\n",
    "# debug\n",
    "print(alpha_median)\n",
    "\n",
    "# calculate the cumulative sum of the weights   \n",
    "alpha_cumsum = torch.cumsum(alpha_median, dim=0)\n",
    "\n",
    "# select the weights which sum up to 0.8    \n",
    "top_80_percent = torch.where[alpha_cumsum <= Config.threshold][0]\n",
    "\n",
    "# debug\n",
    "print(top_80_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_80_tokens = [alpha_dict[idx] for idx in alpha_sort[top_80_percent]]\n",
    "\n",
    "# debug \n",
    "print(top_80_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top 80 percents hidden concepts name\n",
    "top_80_concepts = [concept_dict[i] for i in top_80_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hidden in top_80_tokens:\n",
    "    hidden_concepts = pipe.tokenizer.decode(hidden)\n",
    "    prompt = f'a photo of a {hidden}'\n",
    "    generator = torch.Generator(\"cuda\").manual_seed(Config.seed)\n",
    "    image = pipe(prompt, guidance_scale=7.5,\n",
    "                 generator=generator,\n",
    "                 return_dict=False,\n",
    "                 num_images_per_prompt=1,\n",
    "                 num_inference_steps=Config.num_inference_steps)[0][0]\n",
    "    # Display the image\n",
    "    display(image.resize((224, 224)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ucd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
